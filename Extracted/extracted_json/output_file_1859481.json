{
    "title": "arXiv:1708.07747v2  [cs.LG]  15 Sep 2017",
    "content": {
        "page_content": "arXiv:1708.07747v2  [cs.LG]  15 Sep 2017\nFashion-MNIST: a Novel Image Dataset for\nBenchmarking Machine Learning Algorithms\nHan Xiao\nZalando Research\nMühlenstraße 25, 10243 Berlin\nhan.xiao@zalando.de\nKashif Rasul\nZalando Research\nMühlenstraße 25, 10243 Berlin\nkashif.rasul@zalando.de\nRoland V ollgraf\nZalando Research\nMühlenstraße 25, 10243 Berlin\nroland.vollgraf@zalando.de\nAbstract\nW e present Fashion-MNIST, a new dataset comprising of 28 × 28 grayscale\nimages of 70,000 fashion products from 10 categories, with 7,000 images\nper category. The training set has 60,000 images and the test set has\n10,000 images. Fashion-MNIST is intended to serve as a direct drop-\nin replacement for the original MNIST dataset for benchmark ing machine\nlearning algorithms, as it shares the same image size, data f ormat and the\nstructure of training and testing splits. The dataset is fre ely available at\nhttps://github.com/zalandoresearch/fashion-mnist.\n1 Introduction\nThe MNIST dataset comprising of 10-class handwritten digit s, was ﬁrst introduced by LeCun et al.\n[1998] in 1998. At that time one could not have foreseen the st ellar rise of deep learning tech-\nniques and their performance. Despite the fact that today de ep learning can do so much the sim-\nple MNIST dataset has become the most widely used testbed in d eep learning, surpassing CIF AR-\n10 [Krizhevsky and Hinton, 2009] and ImageNet [Deng et al., 2 009] in its popularity via Google\ntrends1. Despite its simplicity its usage does not seem to be decreas ing despite calls for it in the\ndeep learning community.\nThe reason MNIST is so popular has to do with its size, allowin g deep learning researchers to quickly\ncheck and prototype their algorithms. This is also compleme nted by the fact that all machine learning\nlibraries (e.g. scikit-learn) and deep learning framework s (e.g. T ensorﬂow , Pytorch) provide helper\nfunctions and convenient examples that use MNIST out of the b ox.\nOur aim with this work is to create a good benchmark dataset wh ich has all the accessibility of\nMNIST , namely its small size, straightforward encoding and permissive license. W e took the ap-\nproach of sticking to the 10 classes 70,000 grayscale images in the size of 28 × 28 as in the original\nMNIST . In fact, the only change one needs to use this dataset i s to change the URL from where the\nMNIST dataset is fetched. Moreover, Fashion-MNIST poses a m ore challenging classiﬁcation task\nthan the simple MNIST digits data, whereas the latter has bee n trained to accuracies above 99.7%\nas reported in W an et al. [2013], Ciregan et al. [2012].\nW e also looked at the EMNIST dataset provided by Cohen et al. [ 2017], an extended version of\nMNIST that extends the number of classes by introducing uppe rcase and lowercase characters. How-\n1 https://trends.google.com/trends/explore?date=all&q=mnist,CIFAR,ImageNetever, to be able to use it seamlessly one needs to not only exte nd the deep learning framework’s\nMNIST helpers, but also change the underlying deep neural ne twork to classify these extra classes.\n2 Fashion-MNIST Dataset\nFashion-MNIST is based on the assortment on Zalando’s website2 . Every fashion product on Za-\nlando has a set of pictures shot by professional photographe rs, demonstrating different aspects of\nthe product, i.e. front and back looks, details, looks with m odel and in an outﬁt. The original picture\nhas a light-gray background (hexadecimal color: #fdfdfd) and stored in 762 × 1000 JPEG format.\nFor efﬁciently serving different frontend components, the original picture is resampled with multiple\nresolutions, e.g. large, medium, small, thumbnail and tiny .\nW e use the front look thumbnail images of 70,000 unique products to build Fashion-MNIST. Those\nproducts come from different gender groups: men, women, kid s and neutral. In particular, white-\ncolor products are not included in the dataset as they have lo w contrast to the background. The\nthumbnails ( 51 × 73) are then fed into the following conversion pipeline, which is visualized in\nFigure 1.\n1. Converting the input to a PNG image.\n2. Trimming any edges that are close to the color of the cornerpixels. The “closeness” is\ndeﬁned by the distance within 5% of the maximum possible intensity in RGB space.\n3. Resizing the longest edge of the image to 28 by subsampling the pixels, i.e. some rows and\ncolumns are skipped over.\n4. Sharpening pixels using a Gaussian operator of the radius and standard deviation of 1.0,\nwith increasing effect near outlines.\n5. Extending the shortest edge to 28 and put the image to the center of the canvas.\n6. Negating the intensities of the image.\n7. Converting the image to 8-bit grayscale pixels.\nFigure 1: Diagram of the conversion process used to generate Fashion-MNIST dataset. T wo exam-\nples from dress and sandals categories are depicted, respec tively. Each column represents a step\ndescribed in section 2.\nT able 1: Files contained in the Fashion-MNIST dataset.\nName Description # Examples Size\ntrain-images-idx3-ubyte.gz Training set images 60,000 25 MBytes\ntrain-labels-idx1-ubyte.gz Training set labels 60,000 140 Bytes\nt10k-images-idx3-ubyte.gz T est set images 10,000 4 .2 MBytes\nt10k-labels-idx1-ubyte.gz T est set labels 10,000 92 Bytes\nFor the class labels, we use the silhouette code of the produc t. The silhouette code is manually\nlabeled by the in-house fashion experts and reviewed by a sep arate team at Zalando. Each product\n2 Zalando is the Europe’s largest online fashion platform. http://www.zalando.com\n2contains only one silhouette code. T able 2 gives a summary of all class labels in Fashion-MNIST\nwith examples for each class.\nFinally, the dataset is divided into a training and a test set . The training set receives a randomly-\nselected 6,000 examples from each class. Images and labels are stored in the same ﬁle format as the\nMNIST data set, which is designed for storing vectors and mul tidimensional matrices. The result\nﬁles are listed in T able 1. W e sort examples by their labels wh ile storing, resulting in smaller label\nﬁles after compression comparing to the MNIST . It is also eas ier to retrieve examples with a certain\nclass label. The data shufﬂing job is therefore left to the al gorithm developer.\nT able 2: Class names and example images in Fashion-MNIST dat aset.\nLabel Description Examples\n0 T -Shirt/T op\n1 Trouser\n2 Pullover\n3 Dress\n4 Coat\n5 Sandals\n6 Shirt\n7 Sneaker\n8 Bag\n9 Ankle boots\n3 Experiments\nW e provide some classiﬁcation results in T able 3 to form a ben chmark on this data set. All al-\ngorithms are repeated 5 times by shufﬂing the training data and the average accuracy on the\ntest set is reported. The benchmark on the MNIST dataset is al so included for a side-by-side\ncomparison. A more comprehensive table with explanations o n the algorithms can be found on\nhttps://github.com/zalandoresearch/fashion-mnist.\nT able 3: Benchmark on Fashion-MNIST (Fashion) and MNIST .\nT est Accuracy\nClassiﬁer Parameter Fashion MNIST\nDecisionTreeClassiﬁer criterion=entropy max_depth=10 splitter=best 0.798 0 .873\ncriterion=entropy max_depth=10 splitter=random 0.792 0 .861\ncriterion=entropy max_depth=50 splitter=best 0.789 0 .886\nContinued on next page\n3T able 3 – continued from previous page\nT est Accuracy\nClassiﬁer Parameter Fashion MNIST\ncriterion=entropy max_depth=100 splitter=best 0.789 0 .886\ncriterion=gini max_depth=10 splitter=best 0.788 0 .866\ncriterion=entropy max_depth=50 splitter=random 0.787 0 .883\ncriterion=entropy max_depth=100 splitter=random 0.787 0 .881\ncriterion=gini max_depth=100 splitter=best 0.785 0 .879\ncriterion=gini max_depth=50 splitter=best 0.783 0 .877\ncriterion=gini max_depth=10 splitter=random 0.783 0 .853\ncriterion=gini max_depth=50 splitter=random 0.779 0 .873\ncriterion=gini max_depth=100 splitter=random 0.777 0 .875\nExtraTreeClassiﬁer criterion=gini max_depth=10 splitter=best 0.775 0 .806\ncriterion=entropy max_depth=100 splitter=best 0.775 0 .847\ncriterion=entropy max_depth=10 splitter=best 0.772 0 .810\ncriterion=entropy max_depth=50 splitter=best 0.772 0 .847\ncriterion=gini max_depth=100 splitter=best 0.769 0 .843\ncriterion=gini max_depth=50 splitter=best 0.768 0 .845\ncriterion=entropy max_depth=50 splitter=random 0.752 0 .826\ncriterion=entropy max_depth=100 splitter=random 0.752 0 .828\ncriterion=gini max_depth=50 splitter=random 0.748 0 .824\ncriterion=gini max_depth=100 splitter=random 0.745 0 .820\ncriterion=gini max_depth=10 splitter=random 0.739 0 .737\ncriterion=entropy max_depth=10 splitter=random 0.737 0 .745\nGaussianNB priors=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1] 0.511 0 .524\nGradientBoostingClassiﬁer n_estimators=100 loss=deviance max_depth=10 0.880 0 .969\nn_estimators=50 loss=deviance max_depth=10 0.872 0 .964\nn_estimators=100 loss=deviance max_depth=3 0.862 0 .949\nn_estimators=10 loss=deviance max_depth=10 0.849 0 .933\nn_estimators=50 loss=deviance max_depth=3 0.840 0 .926\nn_estimators=10 loss=deviance max_depth=50 0.795 0 .888\nn_estimators=10 loss=deviance max_depth=3 0.782 0 .846\nKNeighborsClassiﬁer weights=distance n_neighbors=5 p=1 0.854 0 .959\nweights=distance n_neighbors=9 p=1 0.854 0 .955\nweights=uniform n_neighbors=9 p=1 0.853 0 .955\nweights=uniform n_neighbors=5 p=1 0.852 0 .957\nweights=distance n_neighbors=5 p=2 0.852 0 .945\nweights=distance n_neighbors=9 p=2 0.849 0 .944\nweights=uniform n_neighbors=5 p=2 0.849 0 .944\nweights=uniform n_neighbors=9 p=2 0.847 0 .943\nweights=distance n_neighbors=1 p=2 0.839 0 .943\nweights=uniform n_neighbors=1 p=2 0.839 0 .943\nweights=uniform n_neighbors=1 p=1 0.838 0 .955\nweights=distance n_neighbors=1 p=1 0.838 0 .955\nLinearSVC loss=hinge C=1 multi_class=ovr penalty=l2 0.836 0 .917\nloss=hinge C=1 multi_class=crammer_singer penalty=l2 0.835 0 .919\nloss=squared_hinge C=1 multi_class=crammer_singer penalty=l2 0.834 0 .919\nloss=squared_hinge C=1 multi_class=crammer_singer penalty=l1 0.833 0 .919\nloss=hinge C=1 multi_class=crammer_singer penalty=l1 0.833 0 .919\nloss=squared_hinge C=1 multi_class=ovr penalty=l2 0.820 0 .912\nloss=squared_hinge C=10 multi_class=ovr penalty=l2 0.779 0 .885\nloss=squared_hinge C=100 multi_class=ovr penalty=l2 0.776 0 .873\nloss=hinge C=10 multi_class=ovr penalty=l2 0.764 0 .879\nloss=hinge C=100 multi_class=ovr penalty=l2 0.758 0 .872\nContinued on next page\n4T able 3 – continued from previous page\nT est Accuracy\nClassiﬁer Parameter Fashion MNIST\nloss=hinge C=10 multi_class=crammer_singer penalty=l1 0.751 0 .783\nloss=hinge C=10 multi_class=crammer_singer penalty=l2 0.749 0 .816\nloss=squared_hinge C=10 multi_class=crammer_singer penalty=l2 0.748 0 .829\nloss=squared_hinge C=10 multi_class=crammer_singer penalty=l1 0.736 0 .829\nloss=hinge C=100 multi_class=crammer_singer penalty=l1 0.516 0 .759\nloss=hinge C=100 multi_class=crammer_singer penalty=l2 0.496 0 .753\nloss=squared_hinge C=100 multi_class=crammer_singer penalty=l1 0.492 0 .746\nloss=squared_hinge C=100 multi_class=crammer_singer penalty=l2 0.484 0 .737\nLogisticRegression C=1 multi_class=ovr penalty=l1 0.842 0 .917\nC=1 multi_class=ovr penalty=l2 0.841 0 .917\nC=10 multi_class=ovr penalty=l2 0.839 0 .916\nC=10 multi_class=ovr penalty=l1 0.839 0 .909\nC=100 multi_class=ovr penalty=l2 0.836 0 .916\nMLPClassiﬁer activation=relu hidden_layer_sizes=[100] 0.871 0 .972\nactivation=relu hidden_layer_sizes=[100, 10] 0.870 0 .972\nactivation=tanh hidden_layer_sizes=[100] 0.868 0 .962\nactivation=tanh hidden_layer_sizes=[100, 10] 0.863 0 .957\nactivation=relu hidden_layer_sizes=[10, 10] 0.850 0 .936\nactivation=relu hidden_layer_sizes=[10] 0.848 0 .933\nactivation=tanh hidden_layer_sizes=[10, 10] 0.841 0 .921\nactivation=tanh hidden_layer_sizes=[10] 0.840 0 .921\nPassiveAggressiveClassiﬁer C=1 0.776 0 .877\nC=100 0.775 0 .875\nC=10 0.773 0 .880\nPerceptron penalty=l1 0.782 0 .887\npenalty=l2 0.754 0 .845\npenalty=elasticnet 0.726 0 .845\nRandomForestClassiﬁer n_estimators=100 criterion=entropy max_depth=100 0.873 0 .970\nn_estimators=100 criterion=gini max_depth=100 0.872 0 .970\nn_estimators=50 criterion=entropy max_depth=100 0.872 0 .968\nn_estimators=100 criterion=entropy max_depth=50 0.872 0 .969\nn_estimators=50 criterion=entropy max_depth=50 0.871 0 .967\nn_estimators=100 criterion=gini max_depth=50 0.871 0 .971\nn_estimators=50 criterion=gini max_depth=50 0.870 0 .968\nn_estimators=50 criterion=gini max_depth=100 0.869 0 .967\nn_estimators=10 criterion=entropy max_depth=50 0.853 0 .949\nn_estimators=10 criterion=entropy max_depth=100 0.852 0 .949\nn_estimators=10 criterion=gini max_depth=50 0.848 0 .948\nn_estimators=10 criterion=gini max_depth=100 0.847 0 .948\nn_estimators=50 criterion=entropy max_depth=10 0.838 0 .947\nn_estimators=100 criterion=entropy max_depth=10 0.838 0 .950\nn_estimators=100 criterion=gini max_depth=10 0.835 0 .949\nn_estimators=50 criterion=gini max_depth=10 0.834 0 .945\nn_estimators=10 criterion=entropy max_depth=10 0.828 0 .933\nn_estimators=10 criterion=gini max_depth=10 0.825 0 .930\nSGDClassiﬁer loss=hinge penalty=l2 0.819 0 .914\nloss=perceptron penalty=l1 0.818 0 .912\nloss=modified_huber penalty=l1 0.817 0 .910\nloss=modified_huber penalty=l2 0.816 0 .913\nloss=log penalty=elasticnet 0.816 0 .912\nloss=hinge penalty=elasticnet 0.816 0 .913\nContinued on next page\n5T able 3 – continued from previous page\nT est Accuracy\nClassiﬁer Parameter Fashion MNIST\nloss=squared_hinge penalty=elasticnet 0.815 0 .914\nloss=hinge penalty=l1 0.815 0 .911\nloss=log penalty=l1 0.815 0 .910\nloss=perceptron penalty=l2 0.814 0 .913\nloss=perceptron penalty=elasticnet 0.814 0 .912\nloss=squared_hinge penalty=l2 0.814 0 .912\nloss=modified_huber penalty=elasticnet 0.813 0 .914\nloss=log penalty=l2 0.813 0 .913\nloss=squared_hinge penalty=l1 0.813 0 .911\nSVC C=10 kernel=rbf 0.897 0 .973\nC=10 kernel=poly 0.891 0 .976\nC=100 kernel=poly 0.890 0 .978\nC=100 kernel=rbf 0.890 0 .972\nC=1 kernel=rbf 0.879 0 .966\nC=1 kernel=poly 0.873 0 .957\nC=1 kernel=linear 0.839 0 .929\nC=10 kernel=linear 0.829 0 .927\nC=100 kernel=linear 0.827 0 .926\nC=1 kernel=sigmoid 0.678 0 .898\nC=10 kernel=sigmoid 0.671 0 .873\nC=100 kernel=sigmoid 0.664 0 .868\n4 Conclusions\nThis paper introduced Fashion-MNIST, a fashion product ima ges dataset intended to be a drop-\nin replacement of MNIST and whilst providing a more challeng ing alternative for benchmarking\nmachine learning algorithm. The images in Fashion-MNIST ar e converted to a format that matches\nthat of the MNIST dataset, making it immediately compatible with any machine learning package\ncapable of working with the original MNIST dataset.\nReferences\nD. Ciregan, U. Meier, and J. Schmidhuber. Multi-column deepneural networks for image classiﬁ-\ncation. In Computer V ision and P attern Recognition (CVPR), 2012 IEEE Conference on, pages\n3642–3649. IEEE, 2012.\nG. Cohen, S. Afshar, J. T apson, and A. van Schaik. Emnist: an e xtension of mnist to handwritten\nletters. arXiv preprint arXiv:1702.05373, 2017.\nJ. Deng, W . Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Im agenet: A large-scale hierarchical im-\nage database. In Computer V ision and P attern Recognition, 2009. CVPR 2009. IEEE Conference\non, pages 248–255. IEEE, 2009.\nA. Krizhevsky and G. Hinton. Learning multiple layers of fea tures from tiny images. 2009.\nY . LeCun, L. Bottou, Y . Bengio, and P . Haffner. Gradient-bas ed learning applied to document\nrecognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\nL. W an, M. Zeiler, S. Zhang, Y . L. Cun, and R. Fergus. Regulari zation of neural networks using\ndropconnect. In Proceedings of the 30th international conference on machin e learning (ICML-\n13), pages 1058–1066, 2013.\n6"
    }
}